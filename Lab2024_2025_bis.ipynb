{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='./Figs/cs-logo.png' width=200></center>\n",
    "\n",
    "\n",
    "\n",
    "<h6><center></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Sujet 2 : Mouvement et flot optique </center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "L'objectif de ce TP est de mettre en oeuvre les techniques classiques d'estimation du mouvement et de suivi dans des images (Source : Stanford CV course).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher une séquence d'images\n",
    "\n",
    "Dans ce Lab, les vidéos sont fournies sous forme de séries temporelles d'images. Elles se trouvent dans le répertoire [images](./images).\n",
    "Vous avez-ci dessous des fonctions utiles pour charger les images et les visualiser sous la forme d'un court clip vidéo.\n",
    "\n",
    "Il est possible qu'il vous faille installer un codec vidéo comme [FFmpeg](https://www.ffmpeg.org/). Si vous avez conda (ou Anaconda), vous pouvez généralement l'installer avec `conda install -c conda-forge ffmpeg`. Pour Linux/Mac, vous pourrez aussi installer ffmpeg en utilisant `apt-get` ou `brew`. Pour Windows, vous pouvez trouver les instructions d'installation [ici](https://www.wikihow.com/Install-FFmpeg-on-Windows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import animation\n",
    "\n",
    "def load_frames(imgs_dir):\n",
    "    frames = [cv2.imread(os.path.join(imgs_dir, frame),0) \\\n",
    "              for frame in sorted(os.listdir(imgs_dir))]\n",
    "    return frames\n",
    "\n",
    "\n",
    "def animated_frames(frames, figsize=(10,8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    im = ax.imshow(frames[0],cmap='gray')\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(frames[i])\n",
    "        return [im,]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(frames),\n",
    "                                  interval=60, blit=True)\n",
    "\n",
    "    return ani\n",
    "\n",
    "\n",
    "frames = load_frames('images')\n",
    "ani = animated_frames(frames)\n",
    "HTML(ani.to_html5_video())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Méthode de Lucas-Kanade for l'estimation du flot optique\n",
    "\n",
    "## 1.1 Les équations du flot optique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes dites du flot optique sont utilisées pour estimer le mouvement des objets entre deux images consécutives. Par exemple, dans la vidéo ci-dessus, la boîte de thé semble se déplacer vers la gauche. Pour que notre système puisse comprendre que la boîte se déplace vers la gauche, il serait utile de trouver un moyen d'ajouter des vecteurs à la boîte (appelés **vecteurs de flot**) qui pointent vers la gauche, décrivant ainsi son mouvement.\n",
    "\n",
    "Étant donné deux images consécutives, comment pouvons-nous trouver les vecteurs de flot pour la première image qui décrivent la façon dont les objets se déplacent entre les images ? Pour commencer, nous faisons une hypothèse raisonnable appelée **brightness constancy (intensité constante)** : l'intensité du pixel d'un point en mouvement reste la même entre deux images consécutives. En d'autres termes, si l'on choisit n'importe quel pixel de la boîte mobile, sa luminosité reste approximativement la même entre les deux images. Cela signifie que son mouvement ne devrait pas affecter sa luminosité.\n",
    "\n",
    "Considérons l'intensité du pixel (alias la luminosité) $I(x, y, t)$ d'un point $(x, y)$ dans la première image à l'instant $t$. Supposons que le point se soit déplacé à $(x+\\Delta{x}, y+\\Delta{y})$ après le temps $\\Delta{t}$. Selon l'hypothèse de **brightness constancy**, nous pouvons relier les intensités du point dans les deux images à l'aide de l'équation suivante :\n",
    "\n",
    "$$\n",
    "I(x,y,t)=I(x+\\Delta{x},y+\\Delta{y},t+\\Delta{t})\n",
    "$$\n",
    "\n",
    "Pour revenir à l'exemple de la boite en mouvement, cette équation indique simplement que le point que nous avons choisi aura la même intensité même après son déplacement dans l'espace $(\\Delta{x}$ et $\\Delta{y})$ et entre les images $(\\Delta{t})$.\n",
    "À partir de cette simple hypothèse, nous pouvons dériver ce que l'on appelle l' **équation du flot optique**. Pour un point donné $\\mathbf{p}$  et pour n'importe quelle image, l'équation du flux optique est donnée par :\n",
    "\n",
    "$$\n",
    "I_x({\\mathbf{p}})v_{x} +\n",
    "I_y({\\mathbf{p}})v_{y} +\n",
    "I_t({\\mathbf{p}})\n",
    "= 0\n",
    "$$\n",
    "\n",
    "Ici, $I_x$, $I_y$ et $I_t$ sont des dérivées partielles de l'intensité du pixel $I$.\n",
    "$v_{x}$ et $v_{y}$ sont des vecteurs de flot dans les directions $x-$ et $y-$, respectivement. Ce sont ces vecteurs qui nous intéressent ! Si nous pouvons trouver ces deux valeurs, nous serons en mesure de décrire le mouvement de n'importe quel objet entre deux images.\n",
    "\n",
    "Vous vous demandez peut-être comment nous sommes passés de l'hypothèse de l'intensité constante à l'équation du flux optique. Essayez de la dériver vous-même !\n",
    "\n",
    "**a.  En utilisant une approximation de Taylor du premier ordre, déduisez l'équation de flot optique à partir de l'équation d'intensité constante.**\n",
    "\n",
    "*Indication : la réponse est dans le cours - Il suffit juste de le regarder.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "# vous pouvez vous contenter de mettre le numéro de la slide dans laquelle se trouve la solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. L'équation de flot optique peut-elle être résolue pour deux images consécutives sans autre hypothèse?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Parmi $I_x, I_y, I_t, v_x,$ et $v_y$, quelles valeurs peuvent être calculées directement à partir de deux images consécutives ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Quelles valeurs ne peuvent pas être calculées sans informations supplémentaires ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Aperçu de la méthode de Lucas-Kanade\n",
    "\n",
    "L'équation du flot optique pose un problème : il y a deux inconnues que nous voulons résoudre ($v_x$ et $v_y$). Ce problème est connu sous le nom de **problème de l'ouverture (aperture problem)**. En d'autres termes, si l'on se contente de regarder un pixel à la fois dans une \"ouverture\", il est impossible de discerner la véritable direction du mouvement de l'objet en question.\n",
    "\n",
    "La méthode Lucas-Kanade résout ce problème en ajoutant une autre hypothèse : la **cohérence spatiale**. C'est-à-dire que le mouvement du contenu de l'image entre deux images est approximativement constant dans un voisinage du point $p$ considéré.\n",
    "\n",
    "Considérons un voisinage de $p$, $N(p)=\\{p_1,...,p_n\\}$ (par exemple, une fenêtre 3x3 autour de $p$). Si l'on ajoute l'hypothèse de cohérence spatiale à l'équation du flux optique, on constate que la condition suivante doit être remplie :\n",
    "\n",
    "Pour chaque $p_i \\in N(p)$,\n",
    "$$\n",
    "I_{x}(p_i)v_x + I_{y}(p_i)v_y = -I_{t}(p_i)\n",
    "$$\n",
    "\n",
    "Ces équations peuvent être écrites sous forme de matrice $Av=b$, où\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "    I_{x}(p_1) & I_{y}(p_1)\\\\\n",
    "    I_{x}(p_2) & I_{y}(p_2)\\\\\n",
    "    \\vdots & \\vdots\\\\\n",
    "    I_{x}(p_n) & I_{y}(p_n)\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "v =\n",
    "\\begin{bmatrix}\n",
    "    v_{x}\\\\\n",
    "    v_{y}\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "b =\n",
    "\\begin{bmatrix}\n",
    "    -I_{t}(p_1)\\\\\n",
    "    -I_{t}(p_2)\\\\\n",
    "    \\vdots\\\\\n",
    "    -I_{t}(p_n)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Nous pouvons maintenant résoudre les vecteurs de flot (maintenant représentés par $v$) en résolvant le problème des moindres carrés suivant : $A^{T}Av=A^{T}b$.\n",
    "\n",
    "**a. Quelle est la condition pour que cette équation soit résolvable ?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Expliquez pourquoi les coins de Harris pourraient être de bonnes caractéristiques à suivre en utilisant la méthode de Lucas-Kanade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Mise en œuvre de la méthode de Lucas-Kanade\n",
    "\n",
    "\n",
    "Dans cette section, vous allez implémenter la méthode de base de Lucas-Kanade pour le suivi des caractéristiques. Pour cela, il faut d'abord trouver les points clés à suivre. Le détecteur de coins de Harris est généralement utilisé pour initialiser les points clés à suivre avec la méthode de Lucas-Kanade. Pour cela, vous pouvez soit utiliser votre propre détecteur de Harris (Lab 4) ou utiliser l'implémentation fournie dans OpenCV dont la documentation est [ici](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html).\n",
    "\n",
    "Ecrire le code permettant de détecter les points d'intérêts et de les afficher sur les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = load_frames('images')\n",
    "\n",
    "# Detect keypoints to track\n",
    "\n",
    "\n",
    "\n",
    "# Plot kepoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completer la fonction suivante qui implémente la méthode de Lucas-Kanade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade(img1, img2, keypoints, window_size=5):\n",
    "    \"\"\"Estimate flow vector at each keypoint using Lucas-Kanade method.\n",
    "\n",
    "    Args:\n",
    "        img1 - Grayscale image of the current frame. Flow vectors are computed\n",
    "            with respect to this frame.\n",
    "        img2 - Grayscale image of the next frame.\n",
    "        keypoints - Keypoints to track. Numpy array of shape (N, 2).\n",
    "        window_size - Window size to determine the neighborhood of each keypoint.\n",
    "            A window is centered around the current keypoint location.\n",
    "            You may assume that window_size is always an odd number.\n",
    "    Returns:\n",
    "        flow_vectors - Estimated flow vectors for keypoints. flow_vectors[i] is\n",
    "            the flow vector for keypoint[i]. Numpy array of shape (N, 2).\n",
    "\n",
    "    Hints:\n",
    "        - You may use np.linalg.inv to compute inverse matrix\n",
    "    \"\"\"\n",
    "    assert window_size % 2 == 1, \"window_size must be an odd number\"\n",
    "\n",
    "    flow_vectors = []\n",
    "    w = window_size // 2\n",
    "\n",
    "    # Compute partial derivatives\n",
    "    Iy, Ix = np.gradient(img1)\n",
    "    It = img2 - img1\n",
    "\n",
    "    # For each [y, x] in keypoints, estimate flow vector [vy, vx]\n",
    "    # using Lucas-Kanade method and append it to flow_vectors.\n",
    "    for y, x in keypoints:\n",
    "        # Keypoints can be located between integer pixels (subpixel locations).\n",
    "        # For simplicity, we round the keypoint coordinates to nearest integer.\n",
    "        # In order to achieve more accurate results, image brightness at subpixel\n",
    "        # locations can be computed using bilinear interpolation.\n",
    "        y, x = int(round(y)), int(round(x))\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    flow_vectors = np.array(flow_vectors)\n",
    "\n",
    "    return flow_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester maintenant votre fonction sur les deux premières frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucas-Kanade method for optical flow\n",
    "flow_vectors = lucas_kanade(frames[0], frames[1], keypoints, window_size=5)\n",
    "\n",
    "# Plot flow vectors\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "plt.title('Optical flow vectors')\n",
    "\n",
    "for y, x, vy, vx in np.hstack((keypoints, flow_vectors)):\n",
    "    plt.arrow(x, y, vx, vy, head_width=5, head_length=5, color='b')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez avoir ce type de résultat\n",
    "\n",
    "<center><img src='./Figs/optical_flow_vectors.png' width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons estimer la position des points clés dans l'image suivante en ajoutant les vecteurs de flux aux points clés. Ecrivez le code permettant d'estimer et d'afficher la position des points clés dans l'image suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Suivi des caractéristiques dans plusieurs images\n",
    "\n",
    "Vous pouvez maintenant utiliser la méthode de Lucas-Kanade pour suivre les points clés sur plusieurs images. L'idée est simple : calculer les vecteurs de flux aux points clés de la $i$ème image, et ajouter les vecteurs de flux aux points pour suivre les points de la $i+1$ème image. \n",
    "\n",
    "\n",
    "La fonction `track_features` ci-dessous permet de mettre en place ce suivi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_features(\n",
    "    frames,\n",
    "    keypoints,\n",
    "    error_thresh=1.5,\n",
    "    optflow_fn=lucas_kanade,\n",
    "    exclude_border=5,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    \"\"\"Track keypoints over multiple frames\n",
    "\n",
    "    Args:\n",
    "        frames - List of grayscale images with the same shape.\n",
    "        keypoints - Keypoints in frames[0] to start tracking. Numpy array of\n",
    "            shape (N, 2).\n",
    "        error_thresh - Threshold to determine lost tracks.\n",
    "        optflow_fn(img1, img2, keypoints, **kwargs) - Optical flow function.\n",
    "        kwargs - keyword arguments for optflow_fn.\n",
    "\n",
    "    Returns:\n",
    "        trajs - A list containing tracked keypoints in each frame. trajs[i]\n",
    "            is a numpy array of keypoints in frames[i]. The shape of trajs[i]\n",
    "            is (Ni, 2), where Ni is number of tracked points in frames[i].\n",
    "    \"\"\"\n",
    "\n",
    "    kp_curr = keypoints\n",
    "    trajs = [kp_curr]\n",
    "    patch_size = 3  # Take 3x3 patches to compute error\n",
    "    w = patch_size // 2  # patch_size//2 around a pixel\n",
    "\n",
    "    for i in range(len(frames) - 1):\n",
    "        I = frames[i]\n",
    "        J = frames[i + 1]\n",
    "        #flow_vectors = optflow_fn(I, J, kp_curr, **kwargs)\n",
    "        kp_next = kp_curr # + flow_vectors\n",
    "\n",
    "        new_keypoints = []\n",
    "        for yi, xi, yj, xj in np.hstack((kp_curr, kp_next)):\n",
    "            # Declare a keypoint to be 'lost' IF:\n",
    "            # 1. the keypoint falls outside the image J\n",
    "            # 2. the error between points in I and J is larger than threshold\n",
    "\n",
    "            yi = int(round(yi))\n",
    "            xi = int(round(xi))\n",
    "            yj = int(round(yj))\n",
    "            xj = int(round(xj))\n",
    "            # Point falls outside the image\n",
    "            if (\n",
    "                yj > J.shape[0] - exclude_border - 1\n",
    "                or yj < exclude_border\n",
    "                or xj > J.shape[1] - exclude_border - 1\n",
    "                or xj < exclude_border\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            # Compute error between patches in image I and J\n",
    "            patchI = I[yi - w : yi + w + 1, xi - w : xi + w + 1]\n",
    "            patchJ = J[yj - w : yj + w + 1, xj - w : xj + w + 1]\n",
    "            error = compute_error(patchI, patchJ)\n",
    "            if error > error_thresh:\n",
    "                continue\n",
    "\n",
    "            new_keypoints.append([yj, xj])\n",
    "\n",
    "        kp_curr = np.array(new_keypoints)\n",
    "        trajs.append(kp_curr)\n",
    "\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans compléter pour le moment la fonction `compute_error`, compléter la partie du code ci-dessous consistant à extraire les points clés et exécuter le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(patch1, patch2):\n",
    "    \"\"\"Compute MSE between patch1 and patch2\n",
    "\n",
    "        - Normalize patch1 and patch2 each to zero mean, unit variance\n",
    "        - Compute mean square error between patch1 and patch2\n",
    "\n",
    "    Args:\n",
    "        patch1 - Grayscale image patch of shape (patch_size, patch_size)\n",
    "        patch2 - Grayscale image patch of shape (patch_size, patch_size)\n",
    "    Returns:\n",
    "        error - Number representing mismatch between patch1 and patch2\n",
    "    \"\"\"\n",
    "    assert patch1.shape == patch2.shape, \"Different patch shapes\"\n",
    "    error = 0\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "def animated_scatter(frames, trajs, figsize=(10,8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    im = ax.imshow(frames[0])\n",
    "    scat = ax.scatter(trajs[0][:,1], trajs[0][:,0],\n",
    "                      facecolors='none', edgecolors='r')\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(frames[i])\n",
    "        if len(trajs[i]) > 0:\n",
    "            scat.set_offsets(trajs[i][:,[1,0]])\n",
    "        else: # If no trajs to draw\n",
    "            scat.set_offsets([]) # clear the scatter plot\n",
    "\n",
    "        return [im, scat,]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(frames),\n",
    "                                  interval=60, blit=True)\n",
    "\n",
    "    return ani\n",
    "\n",
    "\n",
    "# Detect keypoints to track in the first frame\n",
    "\n",
    "# TO COMPLETE\n",
    "\n",
    "\n",
    "trajs = track_features(frames, keypoints,\n",
    "                       error_thresh=1.5,\n",
    "                       optflow_fn=lucas_kanade,\n",
    "                       window_size=5)\n",
    "ani = animated_scatter(frames,trajs)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Que constatez-vous ?**  Vous devriez remarquer que certains des points s'éloignent et ne sont pas très bien suivis. Il ne faut donc pas garder ces mauvaises traces. Une façon simple de le faire est de comparer les patchs autour des points suivis dans deux images ultérieures. Si le patch autour d'un point n'est PAS similaire au patch autour du point correspondant dans l'image suivante, alors nous déclarons que le point est perdu. Ici, nous allons utiliser l'erreur quadratique moyenne entre deux patchs normalisés comme critère pour les pistes perdues.\n",
    "\n",
    "**Complétez maintenant la fonction `compute_error` ci-dessus et exécutez à nouveau la cellule de code ci-dessous. Vous verrez que beaucoup de points disparaissent dans les images suivantes.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Partie 2 :  Approches de Lucas-Kanade avec représentation multi-résolution et itéraive \n",
    "\n",
    "Dans cette section, nous allons implémenter une version plus simple de la méthode décrite dans [\"Pyramidal Implementation of the Lucas Kanade Feature Tracker\"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.185.585&rep=rep1&type=pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Méthode itérative de Lucas-Kanade\n",
    "\n",
    "Une des limitations de la méthode naïve de Lucas-Kanade est qu'elle ne peut pas suivre de grands mouvements entre les images. Afin de résoudre ce problème, nous pouvons affiner de manière itérative les vecteurs de flot optiques estimés. Voici la description étape par étape de l'algorithme :\n",
    "\n",
    "Soit $p=\\begin{bmatrix}p_x & p_y \\end{bmatrix}^T$ un point sur l'image $I$. Le but est de trouver le vecteur de flux $v=\\begin{bmatrix}v_x & v_y \\end{bmatrix}^T$ tel que $p+v$ est le point correspondant de $p$ sur le cadre suivant $J$.\n",
    "\n",
    "- Initialiser le vecteur flux :\n",
    "$$\n",
    "v=\n",
    "\\begin{bmatrix}\n",
    "    0\\\\0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Calculez la matrice du gradient spatial :\n",
    "$$\n",
    "G=\\sum_{x=p_x-w}^{p_x+w}\\sum_{y=p_y-w}^{p_y+w}\n",
    "\\begin{bmatrix}\n",
    "    I_{x}^2(x,y) & I_{x}(x,y)I_{y}(x,y)\\\\\n",
    "    I_{x}(x,y)I_{y}(x,y) & I_{y}^2(x,y)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **pour $k=1$ à $K$**\n",
    "    - Calcul de la différence temporelle : $\\delta I_k(x, y) = I(x,y)-J(x+g_x+v_x, y+g_y+v_y)$.\n",
    "    - Calculer le vecteur d'inadéquation d'image :\n",
    "\n",
    "$$\n",
    "b_k=\\sum_{x=p_x-w}^{p_x+w}\\sum_{y=p_y-w}^{p_y+w}\n",
    "\\begin{bmatrix}\n",
    "    \\delta I_k(x, y)I_x(x,y)\\\\\n",
    "    \\delta I_k(x, y)I_y(x,y)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "    - Calcul du flot optique: $v^k=G^{-1}b_k$\n",
    "    - Mise à jour pour la prochaine itération: $v := v + v^k$\n",
    "\n",
    "\n",
    "- Return $v$\n",
    "\n",
    "Implémentez la méthode `iterative_lucas_kanade` ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_lucas_kanade(img1, img2, keypoints, window_size=9, num_iters=7, g=None):\n",
    "    \"\"\"Estimate flow vector at each keypoint using iterative Lucas-Kanade method.\n",
    "\n",
    "    Args:\n",
    "        img1 - Grayscale image of the current frame. Flow vectors are computed\n",
    "            with respect to this frame.\n",
    "        img2 - Grayscale image of the next frame.\n",
    "        keypoints - Keypoints to track. Numpy array of shape (N, 2).\n",
    "        window_size - Window size to determine the neighborhood of each keypoint.\n",
    "            A window is centered around the current keypoint location.\n",
    "            You may assume that window_size is always an odd number.\n",
    "        num_iters - Number of iterations to update flow vector.\n",
    "        g - Flow vector guessed from previous pyramid level.\n",
    "    Returns:\n",
    "        flow_vectors - Estimated flow vectors for keypoints. flow_vectors[i] is\n",
    "            the flow vector for keypoint[i]. Numpy array of shape (N, 2).\n",
    "    \"\"\"\n",
    "    assert window_size % 2 == 1, \"window_size must be an odd number\"\n",
    "\n",
    "    # Initialize g as zero vector if not provided\n",
    "    if g is None:\n",
    "        g = np.zeros(keypoints.shape)\n",
    "\n",
    "    flow_vectors = []\n",
    "    w = window_size // 2\n",
    "\n",
    "    # Compute spatial gradients\n",
    "    Iy, Ix = np.gradient(img1)\n",
    "\n",
    "    for y, x, gy, gx in np.hstack((keypoints, g)):\n",
    "        v = np.zeros(2)  # Initialize flow vector as zero vector\n",
    "        y1 = int(round(y))\n",
    "        x1 = int(round(x))\n",
    "\n",
    "        # TODO: Compute inverse of G at point (x1, y1)\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        # Iteratively update flow vector\n",
    "        for k in range(num_iters):\n",
    "            vx, vy = v\n",
    "            # Refined position of the point in the next frame\n",
    "            y2 = int(round(y + gy + vy))\n",
    "            x2 = int(round(x + gx + vx))\n",
    "\n",
    "            # TODO: Compute bk and vk = inv(G) x bk\n",
    "            ### YOUR CODE HERE\n",
    "            pass\n",
    "            ### END YOUR CODE\n",
    "\n",
    "            # Update flow vector by vk\n",
    "            v += vk\n",
    "\n",
    "        vx, vy = v\n",
    "        flow_vectors.append([vy, vx])\n",
    "\n",
    "    return np.array(flow_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executer le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run iterative Lucas-Kanade method\n",
    "flow_vectors = iterative_lucas_kanade(frames[0], frames[1], keypoints)\n",
    "\n",
    "# Plot flow vectors\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "plt.title('Optical flow vectors (iterative LK)')\n",
    "\n",
    "for y, x, vy, vx in np.hstack((keypoints, flow_vectors)):\n",
    "    plt.arrow(x, y, vx, vy, head_width=5, head_length=5, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tracked kepoints\n",
    "new_keypoints = keypoints + flow_vectors\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(frames[1])\n",
    "plt.scatter(new_keypoints[:,1], new_keypoints[:,0],\n",
    "            facecolors='none', edgecolors='r')\n",
    "plt.axis('off')\n",
    "plt.title('Tracked keypoints in the second frame (iterative LK)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Flot optique grossier à fin\n",
    "La méthode itérative ne peut toujours pas suivre les mouvements plus importants. Si nous réduisons l'échelle des images, les grands déplacements seront plus faciles à suivre. D'un autre côté, les mouvements plus petits deviennent plus difficiles à suivre car nous perdons des détails dans les images. Pour résoudre ce problème, nous pouvons représenter les images en multi-échelles, et calculer les vecteurs de flux de l'échelle grossière à l'échelle fine.\n",
    "\n",
    "Votre premier travail consiste donc à construire une pyramide d'images. Pour cela, vous pouvez vous référer à cette [documentation](https://docs.opencv.org/3.4/d4/d1f/tutorial_pyramids.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère maintenant l'algorithme multi-résolution de Lucas-Kanade :\n",
    "\n",
    "Soit $p$ un point de l'image $I$ et $s$ l'échelle de la représentation.\n",
    "- Construire la pyramide de $I$ et $J$: $\\{I^L\\}_{L=0,...,L_m}$ et $\\{J^L\\}_{L=0,...,L_m}$\n",
    "\n",
    "\n",
    "- Initialisation : $g^{L_m}=\n",
    "\\begin{bmatrix}g_{x}^{L_m} & g_{y}^{L_m}\\end{bmatrix}^T=\\begin{bmatrix}0 & 0\\end{bmatrix}^T$\n",
    "\n",
    "\n",
    "- **for $L=L_m$ to $0$ with step of -1**\n",
    "\n",
    "    - Calcul de la position de $p$ sur $I^L$: $p^L=p/s^L$\n",
    "    \n",
    "    - Soit $d^L$ le flot optique au niveau $L$:\n",
    "$$\n",
    "d^L := IterativeLucasKanade(I^L, J^L, p^L, g^L)\n",
    "$$\n",
    "    - Mise à jour pour le prochain niveau : $L-1$: $g^{L-1}=s(g^L+d^L)$\n",
    "    \n",
    "    \n",
    "- Return $d=g^0+d^0$\n",
    "\n",
    "Implementer la fonction `pyramid_lucas_kanade` ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_lucas_kanade(\n",
    "    img1, img2, keypoints, window_size=9, num_iters=7, level=2, scale=2\n",
    "):\n",
    "\n",
    "    \"\"\"Pyramidal Lucas Kanade method\n",
    "\n",
    "    Args:\n",
    "        img1 - same as lucas_kanade\n",
    "        img2 - same as lucas_kanade\n",
    "        keypoints - same as lucas_kanade\n",
    "        window_size - same as lucas_kanade\n",
    "        num_iters - number of iterations to run iterative LK method\n",
    "        level - Max level in image pyramid. Original image is at level 0 of\n",
    "            the pyramid.\n",
    "        scale - scaling factor of image pyramid.\n",
    "\n",
    "    Returns:\n",
    "        d - final flow vectors\n",
    "    \"\"\"\n",
    "\n",
    "    # Build image pyramids of img1 and img2\n",
    "      ### YOUR CODE HERE\n",
    "        \n",
    "    # Initialize pyramidal guess\n",
    "    g = np.zeros(keypoints.shape)\n",
    "\n",
    "    for L in range(level, -1, -1):\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    d = g + d\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executer le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucas-Kanade method for optical flow\n",
    "flow_vectors = pyramid_lucas_kanade(frames[0], frames[1], keypoints)\n",
    "\n",
    "# Plot flow vectors\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "plt.title('Optical flow vectors (pyramid LK)')\n",
    "\n",
    "for y, x, vy, vx in np.hstack((keypoints, flow_vectors)):\n",
    "    plt.arrow(x, y, vx, vy, head_width=3, head_length=3, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tracked kepoints\n",
    "new_keypoints = keypoints + flow_vectors\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(frames[1])\n",
    "plt.scatter(new_keypoints[:,1], new_keypoints[:,0],\n",
    "            facecolors='none', edgecolors='r')\n",
    "plt.axis('off')\n",
    "plt.title('Tracked keypoints in the second frame (pyramid LK)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Suivi d'objet\n",
    "\n",
    "Il s'agit de construire un système de suivi d'objets simple en utilisant la méthode Lucas-Kanade que nous avons implémentée dans les sections précédentes. \n",
    "\n",
    "Cette partie est laissée libre. Il faudra bien expliquer vos hypothèses de départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
